# ğŸ©º MediBot â€“ AI Medical Chatbot using RAG

MediBot is an AI-powered chatbot designed for the medical domain.  
It uses **Retrieval Augmented Generation (RAG)** to provide accurate responses from documents, ensuring domain-specific knowledge and reliability.

---

## ğŸ“Œ Project Overview

The chatbot is built in **three phases**:

1. **Setup Memory for LLM (Vector Database)**
   - Load raw PDF(s).
   - Split documents into **chunks**.
   - Generate **vector embeddings** for each chunk.
   - Store embeddings in **FAISS** (vector database).

2. **Connect Memory with LLM**
   - Setup **Mistral LLM** using HuggingFace.
   - Connect LLM with FAISS for retrieval.
   - Build a **LangChain Retrieval Chain** to handle queries.

3. **Setup User Interface**
   - Build chatbot UI using **Streamlit**.
   - Load vector store into cache for fast retrieval.
   - Implement **Retrieval Augmented Generation (RAG)** pipeline for responses.

---

## ğŸ› ï¸ Tools & Technologies

- **LangChain** â†’ Framework for LLM applications.  
- **HuggingFace** â†’ Hub for pre-trained AI/ML models.  
- **Mistral** â†’ Chosen Large Language Model.  
- **FAISS** â†’ Vector database for storing embeddings.  
- **Streamlit** â†’ Chatbot web interface.  
- **Python** â†’ Core programming language.  
- **VS Code** â†’ IDE for development.

---

## âš™ï¸ Technical Architecture

1. **Input Document(s)** â†’ Upload PDFs.  
2. **Chunking & Embeddings** â†’ Text is chunked and converted into vector embeddings.  
3. **FAISS Vector Store** â†’ Embeddings stored for semantic search.  
4. **RAG Pipeline** â†’ User query is matched against FAISS, relevant chunks retrieved, and passed to LLM.  
5. **LLM (Mistral)** â†’ Generates contextual and accurate response.  
6. **Streamlit UI** â†’ Interactive chatbot interface.  

---

## ğŸš€ How It Works (Step by Step)

1. **Document Processing**
   - Upload medical PDFs.
   - Convert into smaller text chunks.
   - Create embeddings (vector representation).

2. **Knowledge Base Setup**
   - Store embeddings in **FAISS** for semantic retrieval.

3. **LLM Integration**
   - Load Mistral LLM from HuggingFace.
   - Connect LLM with FAISS to answer queries contextually.

4. **User Interaction**
   - Deploy chatbot using Streamlit.
   - Query â†’ FAISS retrieves relevant context â†’ LLM generates response.

---

## ğŸ“ˆ Future Improvements

- ğŸ”‘ Add **authentication** in UI for secure access.  
- ğŸ“‚ Enable **self-upload** of documents for dynamic knowledge base updates.  
- ğŸ“š Support **multiple document embeddings** simultaneously.  
- âœ… Add **unit testing** for RAG components.  
- â˜ï¸ Optionally deploy on **cloud platforms** (AWS, GCP, Azure).  

---

## ğŸ“ Summary

- âœ… Built a **modern AI chatbot** for document-based Q&A.  
- âœ… Developed using a **3-phased modular approach**.  
- âœ… Implemented **Streamlit, LangChain, HuggingFace, Mistral, FAISS**.  
- âœ… Demonstrated an end-to-end **RAG pipeline**.  
- ğŸ”® Scope for further enhancements like multi-doc support, authentication, and deployment.

---

## ğŸ“‚ Project Structure (Example)

